{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepared by [Ali Rifat Kaya](https://www.linkedin.com/in/alirifatkaya/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Import Libraries & Define Functions](#Import-Libraries-&-Define-Functions)\n",
    "2. [Read Data](#Read-Data)\n",
    "3. [Logistic Regression](#Logistic-Regression)\n",
    "4. [Decision Tree Classifier](#Decision-Tree-Classifier)\n",
    "5. [Random Forest Classifier](#Random-Forest-Classifier)\n",
    "6. [Extra Tress Classifier](#Extra-Trees-Classifier)\n",
    "7. [AdaBoost Classifier](#AdaBoost-Classifier)\n",
    "8. [XGBoost Classifier](#XGBoost-Classifier)\n",
    "9. [KNN Classifier](#KNN-Classifier)\n",
    "10. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries & Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T19:45:51.887481Z",
     "start_time": "2020-09-30T19:45:43.535660Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T19:45:51.907628Z",
     "start_time": "2020-09-30T19:45:51.889524Z"
    }
   },
   "outputs": [],
   "source": [
    "def auc_pr(y_test, predict_proba):\n",
    "    p, r, _ = precision_recall_curve(y_test, predict_proba)\n",
    "    return auc(r, p)  # Area Under Curve score\n",
    "# Turns a performance metric into a scorer which help us to use it as\n",
    "# a score function that we can pass as the parameter to the algorithms\n",
    "# needs_proba requires predicted probabilities\n",
    "aucpr = make_scorer(auc_pr, needs_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T19:45:51.948031Z",
     "start_time": "2020-09-30T19:45:51.909654Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T19:45:58.769963Z",
     "start_time": "2020-09-30T19:45:51.950063Z"
    }
   },
   "outputs": [],
   "source": [
    "# reads data into a dataframe\n",
    "raw_data = pd.read_csv('creditcard_new.csv', header=0)\n",
    "# copy data into another dataframe by keeping the original safe\n",
    "df = raw_data.copy()\n",
    "# input matrix and target array\n",
    "X = df.drop(['Class', 'Hours'], axis=1).values  # define the input matrix\n",
    "y = df.Class.values  # the label array (classes)\n",
    "# split the data into the training data (70%) and the test data (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=1)\n",
    "X_train_scaled = scale(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T19:45:58.842492Z",
     "start_time": "2020-09-30T19:45:58.771986Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 337 fraudulent transactions.\n",
      "Test data has 128 fradulent transactions.\n",
      "\n",
      "Distribution of positive class in training data: 0.0017\n",
      "Distribution of positive class in test data: 0.0015\n"
     ]
    }
   ],
   "source": [
    "print('Training data has {} fraudulent transactions.'.format(y_train.sum()))\n",
    "print('Test data has {} fradulent transactions.'.format(y_test.sum()))\n",
    "print('\\nDistribution of positive class in training data: {}'.format(\n",
    "    round((y_train[y_train == 1].size/y_train.size), 4)))\n",
    "print('Distribution of positive class in test data: {}'.format(\n",
    "    round((y_test[y_test == 1].size/y_test.size), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T19:59:23.220489Z",
     "start_time": "2020-09-30T19:45:58.852670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best   : 0.758 using {'C': 0.1, 'class_weight': None, 'solver': 'lbfgs'}\n",
      "Default: 0.756 using {'C': 1.0, 'class_weight': None, 'solver': 'lbfgs'}\n",
      "---------------------------------------------------------------------------------\n",
      "0.750 (0.025) with: {'C': 100, 'class_weight': 'balanced', 'solver': 'newton-cg'}\n",
      "0.750 (0.025) with: {'C': 100, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
      "0.746 (0.036) with: {'C': 100, 'class_weight': 'balanced', 'solver': 'sag'}\n",
      "0.739 (0.043) with: {'C': 100, 'class_weight': 'balanced', 'solver': 'saga'}\n",
      "0.756 (0.029) with: {'C': 100, 'class_weight': None, 'solver': 'newton-cg'}\n",
      "0.756 (0.029) with: {'C': 100, 'class_weight': None, 'solver': 'lbfgs'}\n",
      "0.756 (0.028) with: {'C': 100, 'class_weight': None, 'solver': 'sag'}\n",
      "0.757 (0.027) with: {'C': 100, 'class_weight': None, 'solver': 'saga'}\n",
      "0.749 (0.025) with: {'C': 10, 'class_weight': 'balanced', 'solver': 'newton-cg'}\n",
      "0.749 (0.025) with: {'C': 10, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
      "0.731 (0.055) with: {'C': 10, 'class_weight': 'balanced', 'solver': 'sag'}\n",
      "0.733 (0.039) with: {'C': 10, 'class_weight': 'balanced', 'solver': 'saga'}\n",
      "0.756 (0.029) with: {'C': 10, 'class_weight': None, 'solver': 'newton-cg'}\n",
      "0.756 (0.029) with: {'C': 10, 'class_weight': None, 'solver': 'lbfgs'}\n",
      "0.756 (0.028) with: {'C': 10, 'class_weight': None, 'solver': 'sag'}\n",
      "0.757 (0.027) with: {'C': 10, 'class_weight': None, 'solver': 'saga'}\n",
      "0.749 (0.026) with: {'C': 1.0, 'class_weight': 'balanced', 'solver': 'newton-cg'}\n",
      "0.749 (0.026) with: {'C': 1.0, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
      "0.736 (0.030) with: {'C': 1.0, 'class_weight': 'balanced', 'solver': 'sag'}\n",
      "0.738 (0.034) with: {'C': 1.0, 'class_weight': 'balanced', 'solver': 'saga'}\n",
      "0.756 (0.029) with: {'C': 1.0, 'class_weight': None, 'solver': 'newton-cg'}\n",
      "0.756 (0.028) with: {'C': 1.0, 'class_weight': None, 'solver': 'sag'}\n",
      "0.757 (0.027) with: {'C': 1.0, 'class_weight': None, 'solver': 'saga'}\n",
      "0.744 (0.030) with: {'C': 0.1, 'class_weight': 'balanced', 'solver': 'newton-cg'}\n",
      "0.744 (0.030) with: {'C': 0.1, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
      "0.731 (0.030) with: {'C': 0.1, 'class_weight': 'balanced', 'solver': 'sag'}\n",
      "0.734 (0.027) with: {'C': 0.1, 'class_weight': 'balanced', 'solver': 'saga'}\n",
      "0.758 (0.027) with: {'C': 0.1, 'class_weight': None, 'solver': 'newton-cg'}\n",
      "0.758 (0.027) with: {'C': 0.1, 'class_weight': None, 'solver': 'lbfgs'}\n",
      "0.756 (0.028) with: {'C': 0.1, 'class_weight': None, 'solver': 'sag'}\n",
      "0.757 (0.026) with: {'C': 0.1, 'class_weight': None, 'solver': 'saga'}\n",
      "0.732 (0.033) with: {'C': 0.01, 'class_weight': 'balanced', 'solver': 'newton-cg'}\n",
      "0.732 (0.033) with: {'C': 0.01, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
      "0.731 (0.031) with: {'C': 0.01, 'class_weight': 'balanced', 'solver': 'sag'}\n",
      "0.731 (0.039) with: {'C': 0.01, 'class_weight': 'balanced', 'solver': 'saga'}\n",
      "0.751 (0.029) with: {'C': 0.01, 'class_weight': None, 'solver': 'newton-cg'}\n",
      "0.751 (0.029) with: {'C': 0.01, 'class_weight': None, 'solver': 'lbfgs'}\n",
      "0.753 (0.027) with: {'C': 0.01, 'class_weight': None, 'solver': 'sag'}\n",
      "0.756 (0.026) with: {'C': 0.01, 'class_weight': None, 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "# define hyperparameter space\n",
    "solvers = ['newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "class_weight = ['balanced', None]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers, C=c_values, class_weight=class_weight)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lr, param_grid=grid, n_jobs=-1, cv=cv, scoring=aucpr, error_score=0)\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train)\n",
    "# summarize results\n",
    "print('{:7}: '.format('Best'), end='')\n",
    "print(\"%.3f using %s\" %\n",
    "      (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "rest_scores = []\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    if param == {'C': 1.0, 'class_weight': None, 'solver': 'lbfgs'}:\n",
    "        print('Default: %.3f using %s' % (mean, param))\n",
    "    else:\n",
    "        rest_scores.append('%.3f (%.3f) with: %s' % (mean, stdev, param))\n",
    "print('-'*81)\n",
    "_ = [print(score) for score in rest_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-30T20:00:39.973786Z",
     "start_time": "2020-09-30T19:59:23.226997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best   : 0.761 using {'class_weight': None, 'max_features': 'log2'}\n",
      "Default: 0.734 using {'class_weight': None, 'max_features': None}\n",
      "---------------------------------------------------------------------------------\n",
      "0.750 (0.030) with: {'class_weight': 'balanced', 'max_features': 'sqrt'}\n",
      "0.725 (0.022) with: {'class_weight': 'balanced', 'max_features': 'log2'}\n",
      "0.746 (0.051) with: {'class_weight': 'balanced', 'max_features': None}\n",
      "0.727 (0.064) with: {'class_weight': None, 'max_features': 'sqrt'}\n",
      "0.761 (0.033) with: {'class_weight': None, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "# define hyperparameter space\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "class_weight = ['balanced', None]\n",
    "# define grid search\n",
    "grid = dict(max_features=max_features,\n",
    "            class_weight=class_weight)\n",
    "grid_search = GridSearchCV(estimator=dt,\n",
    "                           param_grid=grid,\n",
    "                           n_jobs=-1,\n",
    "                           cv=cv,\n",
    "                           scoring=aucpr)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print('{:7}: '.format('Best'), end='')\n",
    "print(\"%.3f using %s\" %\n",
    "      (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "rest_scores = []\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    if param == {'class_weight': None, 'max_features': None}:\n",
    "        print('Default: %.3f using %s' % (mean, param))\n",
    "    else:\n",
    "        rest_scores.append('%.3f (%.3f) with: %s' % (mean, stdev, param))\n",
    "print('-' * 81)\n",
    "_ = [print(score) for score in rest_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T12:05:44.663509Z",
     "start_time": "2020-05-22T12:05:44.660069Z"
    }
   },
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T08:48:04.931978Z",
     "start_time": "2020-09-30T20:00:39.973786Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best   : 0.860 using {'class_weight': 'balanced', 'max_features': 'log2', 'n_estimators': 1000}\n",
      "Default: 0.854 using {'class_weight': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "---------------------------------------------------------------------------------\n",
      "0.844 (0.027) with: {'class_weight': 'balanced', 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.857 (0.032) with: {'class_weight': 'balanced', 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.858 (0.034) with: {'class_weight': 'balanced', 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.858 (0.029) with: {'class_weight': 'balanced', 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.853 (0.037) with: {'class_weight': 'balanced', 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.860 (0.029) with: {'class_weight': 'balanced', 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.830 (0.035) with: {'class_weight': 'balanced', 'max_features': None, 'n_estimators': 10}\n",
      "0.841 (0.034) with: {'class_weight': 'balanced', 'max_features': None, 'n_estimators': 100}\n",
      "0.840 (0.037) with: {'class_weight': 'balanced', 'max_features': None, 'n_estimators': 1000}\n",
      "0.847 (0.041) with: {'class_weight': None, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.856 (0.028) with: {'class_weight': None, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.842 (0.036) with: {'class_weight': None, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.853 (0.029) with: {'class_weight': None, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.855 (0.028) with: {'class_weight': None, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.843 (0.028) with: {'class_weight': None, 'max_features': None, 'n_estimators': 10}\n",
      "0.845 (0.026) with: {'class_weight': None, 'max_features': None, 'n_estimators': 100}\n",
      "0.843 (0.030) with: {'class_weight': None, 'max_features': None, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "# define hyperparameter space\n",
    "n_estimators = [10, 100, 1000]\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "class_weight = ['balanced', None]\n",
    "# define grid search\n",
    "grid = dict(n_estimators=n_estimators,\n",
    "            max_features=max_features,\n",
    "            class_weight=class_weight)\n",
    "grid_search = GridSearchCV(estimator=rf,\n",
    "                           param_grid=grid,\n",
    "                           n_jobs=-1,\n",
    "                           cv=cv,\n",
    "                           scoring=aucpr)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print('{:7}: '.format('Best'), end='')\n",
    "print(\"%.3f using %s\" %\n",
    "      (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "rest_scores = []\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    if param == {'class_weight': None, 'max_features': 'sqrt', 'n_estimators': 100}:\n",
    "        print('Default: %.3f using %s' % (mean, param))\n",
    "    else:\n",
    "        rest_scores.append('%.3f (%.3f) with: %s' % (mean, stdev, param))\n",
    "print('-' * 81)\n",
    "_ = [print(score) for score in rest_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T13:02:39.146188Z",
     "start_time": "2020-10-01T08:48:04.947586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best   : 0.864 using {'class_weight': 'balanced', 'max_features': None, 'n_estimators': 1000}\n",
      "Default: 0.861 using {'class_weight': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "---------------------------------------------------------------------------------\n",
      "0.855 (0.038) with: {'class_weight': 'balanced', 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.861 (0.027) with: {'class_weight': 'balanced', 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.863 (0.030) with: {'class_weight': 'balanced', 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.853 (0.034) with: {'class_weight': 'balanced', 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.860 (0.029) with: {'class_weight': 'balanced', 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.862 (0.029) with: {'class_weight': 'balanced', 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.858 (0.027) with: {'class_weight': 'balanced', 'max_features': None, 'n_estimators': 10}\n",
      "0.863 (0.032) with: {'class_weight': 'balanced', 'max_features': None, 'n_estimators': 100}\n",
      "0.864 (0.029) with: {'class_weight': 'balanced', 'max_features': None, 'n_estimators': 1000}\n",
      "0.851 (0.028) with: {'class_weight': None, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.863 (0.029) with: {'class_weight': None, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.858 (0.033) with: {'class_weight': None, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.858 (0.029) with: {'class_weight': None, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.863 (0.029) with: {'class_weight': None, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.862 (0.025) with: {'class_weight': None, 'max_features': None, 'n_estimators': 10}\n",
      "0.859 (0.027) with: {'class_weight': None, 'max_features': None, 'n_estimators': 100}\n",
      "0.862 (0.028) with: {'class_weight': None, 'max_features': None, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier()\n",
    "# use the hyperparameter space for RandomForestClassifier\n",
    "grid_search = GridSearchCV(estimator=et,\n",
    "                           param_grid=grid,\n",
    "                           n_jobs=-1,\n",
    "                           cv=cv,\n",
    "                           scoring=aucpr)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print('{:7}: '.format('Best'), end='')\n",
    "print(\"%.3f using %s\" %\n",
    "      (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "rest_scores = []\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    if param == {'class_weight': None, 'max_features': 'sqrt', 'n_estimators': 100}:\n",
    "        print('Default: %.3f using %s' % (mean, param))\n",
    "    else:\n",
    "        rest_scores.append('%.3f (%.3f) with: %s' % (mean, stdev, param))\n",
    "print('-' * 81)\n",
    "_ = [print(score) for score in rest_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T17:05:45.285880Z",
     "start_time": "2020-10-01T13:02:39.146188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best   : 0.829 using {'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "Default: 0.761 using {'learning_rate': 1, 'n_estimators': 50}\n",
      "---------------------------------------------------------------------------------\n",
      "0.732 (0.030) with: {'learning_rate': 0.0001, 'n_estimators': 10}\n",
      "0.732 (0.030) with: {'learning_rate': 0.0001, 'n_estimators': 50}\n",
      "0.732 (0.030) with: {'learning_rate': 0.0001, 'n_estimators': 100}\n",
      "0.739 (0.040) with: {'learning_rate': 0.0001, 'n_estimators': 1000}\n",
      "0.732 (0.030) with: {'learning_rate': 0.001, 'n_estimators': 10}\n",
      "0.733 (0.031) with: {'learning_rate': 0.001, 'n_estimators': 50}\n",
      "0.739 (0.040) with: {'learning_rate': 0.001, 'n_estimators': 100}\n",
      "0.739 (0.036) with: {'learning_rate': 0.001, 'n_estimators': 1000}\n",
      "0.732 (0.032) with: {'learning_rate': 0.01, 'n_estimators': 10}\n",
      "0.747 (0.030) with: {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "0.740 (0.035) with: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "0.766 (0.031) with: {'learning_rate': 0.01, 'n_estimators': 1000}\n",
      "0.743 (0.032) with: {'learning_rate': 0.1, 'n_estimators': 10}\n",
      "0.769 (0.034) with: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "0.774 (0.023) with: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "0.829 (0.041) with: {'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "0.697 (0.068) with: {'learning_rate': 1, 'n_estimators': 10}\n",
      "0.808 (0.052) with: {'learning_rate': 1, 'n_estimators': 100}\n",
      "0.818 (0.059) with: {'learning_rate': 1, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier()\n",
    "# define hyperparameter space\n",
    "n_estimators = [10, 50, 100, 1000]\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "# define grid search\n",
    "grid = dict(n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate)\n",
    "grid_search = GridSearchCV(estimator=adaboost,\n",
    "                           param_grid=grid,\n",
    "                           n_jobs=-1,\n",
    "                           cv=cv,\n",
    "                           scoring=aucpr)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print('{:7}: '.format('Best'), end='')\n",
    "print(\"%.3f using %s\" %\n",
    "      (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "rest_scores = []\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    if param == {'learning_rate': 1, 'n_estimators': 50}:\n",
    "        print('Default: %.3f using %s' % (mean, param))\n",
    "    else:\n",
    "        rest_scores.append('%.3f (%.3f) with: %s' % (mean, stdev, param))\n",
    "print('-' * 81)\n",
    "_ = [print(score) for score in rest_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T06:28:39.418556Z",
     "start_time": "2020-10-01T17:05:45.285880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best   : 0.828 using {'learning_rate': 0.001, 'max_features': None, 'n_estimators': 1000}\n",
      "Default: 0.604 using {'learning_rate': 0.1, 'max_features': None, 'n_estimators': 100}\n",
      "---------------------------------------------------------------------------------\n",
      "0.782 (0.028) with: {'learning_rate': 0.0001, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.801 (0.025) with: {'learning_rate': 0.0001, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.806 (0.027) with: {'learning_rate': 0.0001, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.770 (0.038) with: {'learning_rate': 0.0001, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.798 (0.028) with: {'learning_rate': 0.0001, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.802 (0.029) with: {'learning_rate': 0.0001, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.809 (0.024) with: {'learning_rate': 0.0001, 'max_features': None, 'n_estimators': 10}\n",
      "0.808 (0.024) with: {'learning_rate': 0.0001, 'max_features': None, 'n_estimators': 100}\n",
      "0.812 (0.019) with: {'learning_rate': 0.0001, 'max_features': None, 'n_estimators': 1000}\n",
      "0.778 (0.027) with: {'learning_rate': 0.001, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.803 (0.032) with: {'learning_rate': 0.001, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.812 (0.027) with: {'learning_rate': 0.001, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.790 (0.036) with: {'learning_rate': 0.001, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.795 (0.028) with: {'learning_rate': 0.001, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.807 (0.026) with: {'learning_rate': 0.001, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.808 (0.024) with: {'learning_rate': 0.001, 'max_features': None, 'n_estimators': 10}\n",
      "0.813 (0.020) with: {'learning_rate': 0.001, 'max_features': None, 'n_estimators': 100}\n",
      "0.828 (0.015) with: {'learning_rate': 0.001, 'max_features': None, 'n_estimators': 1000}\n",
      "0.749 (0.030) with: {'learning_rate': 0.01, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.786 (0.044) with: {'learning_rate': 0.01, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.773 (0.064) with: {'learning_rate': 0.01, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.756 (0.028) with: {'learning_rate': 0.01, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.788 (0.035) with: {'learning_rate': 0.01, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.732 (0.081) with: {'learning_rate': 0.01, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.789 (0.055) with: {'learning_rate': 0.01, 'max_features': None, 'n_estimators': 10}\n",
      "0.818 (0.022) with: {'learning_rate': 0.01, 'max_features': None, 'n_estimators': 100}\n",
      "0.725 (0.072) with: {'learning_rate': 0.01, 'max_features': None, 'n_estimators': 1000}\n",
      "0.497 (0.196) with: {'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.601 (0.058) with: {'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.274 (0.105) with: {'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.672 (0.102) with: {'learning_rate': 0.1, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.509 (0.150) with: {'learning_rate': 0.1, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.538 (0.199) with: {'learning_rate': 0.1, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.625 (0.209) with: {'learning_rate': 0.1, 'max_features': None, 'n_estimators': 10}\n",
      "0.604 (0.199) with: {'learning_rate': 0.1, 'max_features': None, 'n_estimators': 1000}\n",
      "0.381 (0.129) with: {'learning_rate': 1, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.272 (0.115) with: {'learning_rate': 1, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.401 (0.163) with: {'learning_rate': 1, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.441 (0.177) with: {'learning_rate': 1, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.403 (0.181) with: {'learning_rate': 1, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.435 (0.036) with: {'learning_rate': 1, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.455 (0.257) with: {'learning_rate': 1, 'max_features': None, 'n_estimators': 10}\n",
      "0.455 (0.257) with: {'learning_rate': 1, 'max_features': None, 'n_estimators': 100}\n",
      "0.454 (0.257) with: {'learning_rate': 1, 'max_features': None, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "# define hyperparameter space\n",
    "n_estimators = [10, 100, 1000]\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "# define grid search\n",
    "grid = dict(n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            max_features=max_features)\n",
    "grid_search = GridSearchCV(estimator=gb,\n",
    "                           param_grid=grid,\n",
    "                           n_jobs=-1,\n",
    "                           cv=cv,\n",
    "                           scoring=aucpr)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print('{:7}: '.format('Best'), end='')\n",
    "print(\"%.3f using %s\" %\n",
    "      (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "rest_scores = []\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    if param == {'learning_rate': 0.1, 'max_features': None, 'n_estimators': 100}:\n",
    "        print('Default: %.3f using %s' % (mean, param))\n",
    "    else:\n",
    "        rest_scores.append('%.3f (%.3f) with: %s' % (mean, stdev, param))\n",
    "print('-' * 81)\n",
    "_ = [print(score) for score in rest_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T07:34:58.951865Z",
     "start_time": "2020-10-02T06:28:39.424381Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best   : 0.861 using {'colsample_bytree': 0.2, 'eta': 0.5}\n",
      "Default: 0.850 using {'colsample_bytree': 1.0, 'eta': 0.3}\n",
      "---------------------------------------------------------------------------------\n",
      "0.816 (0.037) with: {'colsample_bytree': 0.2, 'eta': 0.001}\n",
      "0.822 (0.035) with: {'colsample_bytree': 0.2, 'eta': 0.01}\n",
      "0.858 (0.027) with: {'colsample_bytree': 0.2, 'eta': 0.1}\n",
      "0.860 (0.030) with: {'colsample_bytree': 0.2, 'eta': 0.3}\n",
      "0.861 (0.024) with: {'colsample_bytree': 0.2, 'eta': 0.5}\n",
      "0.836 (0.030) with: {'colsample_bytree': 0.2, 'eta': 1}\n",
      "0.832 (0.031) with: {'colsample_bytree': 0.4, 'eta': 0.001}\n",
      "0.834 (0.029) with: {'colsample_bytree': 0.4, 'eta': 0.01}\n",
      "0.859 (0.025) with: {'colsample_bytree': 0.4, 'eta': 0.1}\n",
      "0.855 (0.035) with: {'colsample_bytree': 0.4, 'eta': 0.3}\n",
      "0.853 (0.025) with: {'colsample_bytree': 0.4, 'eta': 0.5}\n",
      "0.845 (0.041) with: {'colsample_bytree': 0.4, 'eta': 1}\n",
      "0.844 (0.029) with: {'colsample_bytree': 0.6, 'eta': 0.001}\n",
      "0.845 (0.027) with: {'colsample_bytree': 0.6, 'eta': 0.01}\n",
      "0.857 (0.029) with: {'colsample_bytree': 0.6, 'eta': 0.1}\n",
      "0.857 (0.031) with: {'colsample_bytree': 0.6, 'eta': 0.3}\n",
      "0.852 (0.030) with: {'colsample_bytree': 0.6, 'eta': 0.5}\n",
      "0.851 (0.028) with: {'colsample_bytree': 0.6, 'eta': 1}\n",
      "0.844 (0.031) with: {'colsample_bytree': 0.8, 'eta': 0.001}\n",
      "0.851 (0.028) with: {'colsample_bytree': 0.8, 'eta': 0.01}\n",
      "0.856 (0.030) with: {'colsample_bytree': 0.8, 'eta': 0.1}\n",
      "0.860 (0.028) with: {'colsample_bytree': 0.8, 'eta': 0.3}\n",
      "0.855 (0.026) with: {'colsample_bytree': 0.8, 'eta': 0.5}\n",
      "0.857 (0.028) with: {'colsample_bytree': 0.8, 'eta': 1}\n",
      "0.834 (0.027) with: {'colsample_bytree': 1.0, 'eta': 0.001}\n",
      "0.854 (0.023) with: {'colsample_bytree': 1.0, 'eta': 0.01}\n",
      "0.852 (0.024) with: {'colsample_bytree': 1.0, 'eta': 0.1}\n",
      "0.852 (0.026) with: {'colsample_bytree': 1.0, 'eta': 0.5}\n",
      "0.847 (0.033) with: {'colsample_bytree': 1.0, 'eta': 1}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "# define hyperparameter space\n",
    "eta = [0.001, 0.01, 0.1, 0.3, 0.5, 1]\n",
    "colsample_bytree = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "# define grid search\n",
    "grid = dict(eta=eta,\n",
    "            colsample_bytree=colsample_bytree)\n",
    "grid_search = GridSearchCV(estimator=xgb,\n",
    "                           param_grid=grid,\n",
    "                           n_jobs=-1,\n",
    "                           cv=cv,\n",
    "                           scoring=aucpr)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print('{:7}: '.format('Best'), end='')\n",
    "print(\"%.3f using %s\" %\n",
    "      (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "rest_scores = []\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    if param == {'colsample_bytree': 1.0, 'eta': 0.3}:\n",
    "        print('Default: %.3f using %s' % (mean, param))\n",
    "    else:\n",
    "        rest_scores.append('%.3f (%.3f) with: %s' % (mean, stdev, param))\n",
    "print('-' * 81)\n",
    "_ = [print(score) for score in rest_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since in the [KNN Hyperparameter Optimization](knn_hyperparameter_optimization.ipynb) notebook, I used intervals to select the best score. The best score was `n_neighbors=3`. However, it is important to see the performance of `n_neighbors=4` before having a final decision. Even though, the difference is tiny, I will go with `n_neighbors=3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T08:23:23.503160Z",
     "start_time": "2020-10-02T08:01:06.769327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859 using {'n_neighbors': 3}\n",
      "0.857 using {'n_neighbors': 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "# define hyperparameter space\n",
    "n_neighbors = [3, 4]\n",
    "# define grid search\n",
    "grid = dict(n_neighbors=n_neighbors)\n",
    "grid_search = GridSearchCV(estimator=knn,\n",
    "                           param_grid=grid,\n",
    "                           n_jobs=-1,\n",
    "                           cv=cv,\n",
    "                           scoring=aucpr)\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train)\n",
    "# summarize results\n",
    "print(\"%.3f using %s\" %\n",
    "      (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    if param != grid_result.best_params_:\n",
    "        print('%.3f using %s' % (mean, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the hyperparameter optimization, I tried to chose the most important hyperparameters and had to chose a narrow hyperparameter space due to the limited computing power. However, I obtained moderate and great improvement on the performances of the algorithms. The table shows the default, the tuned performance and the performance improvement.\n",
    "\n",
    "| Algorithm                      | Default Parameters | Tuned Parameters | Change |\n",
    "|--------------------------------|--------------------|------------------|--------|\n",
    "| Logistic Regression            | 0.756 | 0.758 | 0.002 |\n",
    "| Decision Tree Classifier       | 0.734 | 0.761 | 0.027 |\n",
    "| Random Forest Classifier       | 0.854 | 0.860 | 0.060 |\n",
    "| Extra Trees Classifier         | 0.861 | 0.864 | 0.003 |\n",
    "| AdaBoost Classifier            | 0.761 | 0.829 | 0.680 |\n",
    "| Gradient Boosting Classifier   | 0.604 | 0.828 | 0.224 |\n",
    "| XGBoost Classifier             | 0.850 | 0.861 | 0.011 |\n",
    "| K-Nearest Neighbors Classifier | 0.859 | 0.857 | -0.002|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is important to remember that the final results will come with the test set and I will compare the performance of the algorithms with the default parameters and the tuned parameters. At the end, the best algorithms to detect _fraudulent transactions_ will be ready for the deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next stage is to [test the algorithms with tuned parameters](final_evaluation.ipynb)."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "306px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
